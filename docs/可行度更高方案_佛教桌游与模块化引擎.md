# 可行度更高方案：佛教世界观经济学桌游 + 模块化与引擎抽象

> 综合前述 LLM 批判结论，以「佛教世界观经济学桌游」为主产品，通过模块化设计，在具体项目完成后视情况抽象出桌游设计引擎。  
> **本版已综合全部批判**：工作区批判、Red Team、YAML+脚本混合、规则形式化、LLM 校验闭环、回测目标务实化、Phase 1 时间 4–8 周与成功标准、调试支持、选择树抽象、机制矩阵与不穷举等。  
> 日期：2026-01-29

---

## 一、中心思想与优先级调整

### 1.1 中心思想（你明确的目标）

1. **主目标**：做一款与**佛教世界观、经济学**相关的桌游（功德轮回是具体载体）。
2. **次目标**：在开发过程中**模块化**实现，项目完成后**视情况**抽象出一个可复用的桌游设计引擎。

### 1.2 与先前方案的差异

| 维度 | 先前方案（批判对象） | 本方案（可行度更高） |
|------|----------------------|----------------------|
| **主次关系** | 引擎为主，游戏为用例 | **游戏为主**，引擎为「可能产出」 |
| **引擎定位** | 一开始就做「通用引擎」 | 先做**功德轮回专用**，再**有条件地**抽象 |
| **LLM 角色** | 自然语言 → 完整 YAML 规则 | **辅助**：建议、片段生成、解释，不做全自动 |
| **支持范围** | 声称覆盖 80%+ RPG 桌游 | **不承诺**通用；抽象出的引擎只保证「类似半合作 RPG」可复用 |
| **验证顺序** | 先有引擎再验证游戏 | **先有可玩、可测的游戏**，再谈抽象 |

### 1.3 这样调整带来的好处

- **需求真实**：佛教经济学桌游是你要做的产品，不会为「假想中的通用用户」过度设计。
- **范围可控**：不承诺支持 Gloomhaven、Twilight Imperium，只解决功德轮回及类似结构游戏。
- **引擎是结果而非前提**：抽象引擎变成「做完项目后的复盘与提炼」，而不是一开始就背负「通用」包袱。
- **与批判结论一致**：缩小范围、降低 LLM 期望、分阶段验证、承认局限性。

---

## 二、产品边界：佛教世界观经济学桌游

### 2.1 内容边界

- **世界观**：佛教概念（福、慧、劫难、渡化、皈依、发愿、众生、因果等）作为资源、行动、叙事的主干。
- **经济学**：资源稀缺、交换、投资、代价与收益、公共品（团队劫难/渡化）、个人激励（发愿、排名）。
- **游戏形态**：半合作 RPG 桌游（团队胜利条件 + 个人计分），2–4 人，回合制，卡牌（事件/众生/发愿）+ 骰子。

不追求：纯抽象引擎、支持任意类型桌游、LLM 一键生成完整规则。

### 2.2 功能边界（MVP → 后续）

| 阶段 | 功能 | 不做 / 延后 |
|------|------|-------------|
| **MVP** | 规则明确、单局可跑、批量模拟、基础指标（胜率、回合数、劫难/渡化曲线） | 隐藏信息、叛徒、RL、通用引擎 |
| **迭代 1** | 分支选择（皈依/大乘/密宗等）、简单策略智能体、报告/图表 | 完整 LLM 生成规则 |
| **迭代 2** | LLM 辅助（自然语言→规则片段、平衡建议、FAQ）、可选可视化 | 支持其他 IP 的桌游 |
| **抽象（视情况）** | 从功德轮回中抽出「阶段/行动/资源/牌堆/胜负」通用层 | 不承诺覆盖所有 RPG 桌游 |

---

## 三、模块化设计原则（为日后抽象打基础）

### 3.1 目标

- **当前**：功德轮回开发时，逻辑按「模块」划分，便于维护和迭代。
- **日后**：若抽象引擎，只需把「游戏特定」与「通用结构」分离，而不是推倒重写。

### 3.2 建议的模块划分

```
功德轮回项目（产品）
├── 游戏内容（佛教世界观、经济学）
│   ├── 资源与术语定义（福、慧、财富、劫难、渡化…）
│   ├── 角色与初始状态（农夫、商人、学者、僧侣）
│   ├── 事件卡、众生卡、发愿卡（数据表）
│   ├── 行动定义（修行、渡化、布施…）及其效果
│   └── 胜负与计分（团队条件、个人分）
│
├── 游戏流程（可被抽象为「通用结构」）
│   ├── 回合与阶段顺序（事件→众生→行动→结算…）
│   ├── 阶段内行动次数、回合数上限
│   ├── 牌堆抽取与结算
│   └── 分支选择触发（皈依、大乘、密宗…）
│
├── 模拟与回测（最容易抽象）
│   ├── 随机种子与可复现
│   ├── 单局执行循环
│   ├── 批量跑局与汇总指标
│   └── 简单智能体（随机 / 规则型）
│
└── 工具与交互（产品体验，抽象时可选）
    ├── 配置编辑（表格/表单 或 简单 YAML）
    ├── 报告与图表
    └── LLM 辅助（对话、片段生成、解释）
```

- **游戏内容**：强绑定佛教桌游，抽象时保留为「示例数据」或「默认包」。
- **游戏流程**：用通用术语（phase, action, resource, deck, condition）实现，便于日后抽成「引擎规则层」。
- **模拟与回测**：与具体世界观无关，最容易变成可复用引擎核心。
- **工具与交互**：先服务本项目，若抽象引擎再考虑「通用配置格式 + 通用报告」。

### 3.3 命名与接口的「可抽象」约定

- 代码里**引擎向**命名用英文、通用词：`phase`, `action`, `resource`, `deck`, `global_state`, `player_state`, `round`, `trigger`, `condition`。
- **佛教专有**只出现在：数据表、文案、以及调用上述通用接口时的参数（如 `resource_id: "merit"`）。
- 这样将来抽引擎时，只需把「功德轮回的数据与文案」从「流程与模拟」中剥开，而不是改一大片专有命名。

---

## 四、技术路线（采纳批判后的保守选择）

### 4.1 规则表达：YAML/表 + Python 混合（采纳「配置+脚本」批判）

- **原则**：不追求「全 YAML」。复杂游戏的**规则例外**远多于「规则」，纯配置会要么表达力不足，要么配置爆炸；采用**数据用配置、逻辑用代码**的混合模式。
- **MVP**：  
  - **数据**：资源、角色、卡牌表、行动列表、数值（渡化门槛、回合数等）用 **YAML/JSON/CSV** 或 Python 数据结构。  
  - **逻辑**：复杂条件、特殊效果、边界情况（如「若财富不足扣到 0 且福-1」）用 **Python 函数**（如 `def can_liberate(state): ...`、`def apply_event(state, card): ...`）。  
  - **卡牌效果**：简单效果（`gain: { merit: 1 }`）可配置；复杂效果（条件伤害、多目标、时序依赖）用 **Python 片段** 实现，LLM 生成 Python 比生成复杂自定义 DSL 更可控。
- **迭代 1**：若重复模式多，再引入小范围 YAML（阶段、行动 id 列表、简单条件）；复杂逻辑仍保留在 Python。
- **抽象时**：若做引擎，定义「最小通用 schema」+ **效果脚本接口**（如 `effect_fn(state, ctx) -> state_delta`），功德轮回作为实现之一。

### 4.2 模拟与回测（采纳「半合作回测目标」批判）

- **MVP**：  
  - 单局：固定种子，按回合阶段执行，记录轨迹（回合、阶段、玩家、动作、状态快照）。  
  - 批量：多局、多种子，汇总胜率、回合数、劫难/渡化/福慧曲线等。  
  - 智能体：**仅随机 + 1～2 个规则型**（如「优先渡化」「劫难高时优先护法」），不做 RL。
- **回测目标（务实界定）**：  
  - **做**：**经济压力测试**——会不会死机、资源是否无限膨胀/崩溃、规则是否自洽、数值版本对比（如 v3.5 vs v3.6）。  
  - **不做**：不指望 AI 测出「社交平衡性」或「谈判/欺骗」体验；半合作的核心体验（隐藏发愿、个人目标）在「完全信息」模拟下会弱化，这是已知局限。
- **不目标**：预测真人胜率、复现隐藏信息或叛徒心理。

### 4.3 LLM（DeepSeek）的角色与校验约束（采纳「LLM 不可控」批判）

- **定位**：**辅助**，而非「一键生成完整规则」。LLM 在精确结构化输出上仍有局限（复杂嵌套易错、对 schema 依赖 prompt 质量），「自动修正循环」可能死循环或越改越错，因此**以人审为主**。
- **建议用途**：  
  - 根据自然语言**生成规则/代码片段**（如一段新行动、一个新分支选项、一段 Python 效果函数），由人**粘贴进项目并人工校验**。  
  - **解释**现有规则或指标（「为什么这版胜率低？」）。  
  - **平衡与设计建议**（「若提高渡化门槛，可能带来……」），供设计师参考。  
- **不做**：  
  - 不要求 LLM 一次输出整份可运行配置并自动生效。  
  - 不承诺「模糊需求」（如「让游戏更有趣」）能有效处理；模糊时 LLM 输出**多个候选方案**供人选择。  
- **若做「LLM 生成 → 引擎执行」的闭环（可选、迭代 2）**：  
  - **Schema 强约束**：用 Pydantic/JSON Schema 限定字段、类型、枚举、表达式语法。  
  - **静态校验**：引用是否存在、数值范围、触发条件是否可达、循环依赖检测。  
  - **动态校验**：最小对局 smoke test（跑 1 局或 10 局），验证不崩、不死循环。  
  - **失败→修复**：校验错误信息喂回 DeepSeek 让其改片段，并设**修正次数上限**，避免死循环；仍以人终审为准。

### 4.4 隐藏信息、叛徒、复杂多智能体

- **一律延后**：MVP 与迭代 1 只做**完全信息**、**无叛徒**的模拟。  
- 若未来要做「带隐藏目标的半合作」或「叛徒」体验，再单独列为 Phase 5+，并接受：模拟难度高、可能需要专门研究（信念状态、多智能体 RL 等）。

---

## 五、阶段计划（可行度优先）

### Phase 1：可玩、可测的功德轮回（主产品 MVP）

- **时间估计（采纳批判）**：**4–8 周**（2–4 周过于乐观）。仅「规则固化 + 边界情况」就可能占 2–3 周；最小引擎（阶段循环、行动执行、骰子、牌堆）再占 2–3 周；验证与对齐旧脚本再占 1–2 周。业余开发取上限，有经验者可取下限。

| 项目 | 内容 | 产出 |
|------|------|------|
| 规则固化 | 以 v3.6（或当前主版本）为准，**Python + 表数据** 实现回合、阶段、行动、牌堆、胜负；复杂条件与边界（如「财富不足扣到 0 且福-1」）用 Python 函数 | 单局可跑、可复现 |
| 规则一致性 | 处理规则优先级、多效果顺序、边界情况；必要时引入简单「效果层」或执行顺序约定，避免规则冲突（不追求 MTG 级 Layer，先约定即可） | 无歧义、可重复执行 |
| 对局日志 | 每步记录 (round, phase, player, action, state_delta) | 可回放、可分析 |
| 批量模拟 | 固定种子、N 局（建议先 100/500，再 1000）、汇总胜率/回合数/劫难/渡化/资源曲线 | 一份汇总指标（JSON + 简单图表） |
| 简单智能体 | 随机 + 1 个规则型（如贪心渡化） | 对比「随机 vs 规则」下的指标差异 |
| 模块划分 | 按 3.2 的「游戏内容 / 流程 / 模拟 / 工具」拆分目录与职责 | 代码结构清晰，便于后续抽象 |
| **调试支持** | **必须**支持「单局可暂停、查看当前状态（资源、牌堆、阶段、玩家状态）」；纯 JSON 日志不够，需要能定位「哪一步、哪个变量」导致异常（采纳「可视化调试器」批判） | 可定位规则/实现 bug |

**成功标准与验证计划（采纳批判）**：  
- **MVP 成功指标**：功德轮回 v3.6 用当前实现跑通；**1000 局**回测稳定无崩溃；输出关键指标（胜率、平均回合数、劫难/渡化曲线）与**旧版脚本（若有）差异 &lt;5%**，或差异可解释（如规则微调）。  
- **验证方式**：与 Archive 内旧模拟器同规则、同种子对比若干局；或人工抽检若干轨迹与规则书逐条对照。  
- **不验证**：不要求「通用引擎」、不要求第二款游戏在本阶段落地。

### Phase 2：分支选择与迭代体验

- **选择树抽象（采纳「避免 flag 泥潭」批判）**：不把「皈依/大乘/密宗」做成零散的 `flag + modify_action`，而是抽象为**可组合的 progression module**（类似 talent tree / stance）：  
  - **统一语义**：触发条件（回合/阶段/前置选择）、选项列表、每选项的「赋能」（解锁行动 / 修改数值 / 添加结算规则 / 影响计分）。  
  - **冲突与前置**：明确定义「互斥选项」「前置条件」（如「仅皈依者可选大乘」），避免后期规则脆裂、难以维护。  
  - 实现上可以是「配置表 + 少量 Python 校验」，便于日后引擎抽象时复用。

| 项目 | 内容 | 产出 |
|------|------|------|
| 分支选择 | 皈依、发愿大乘、修行密宗等，用 **progression module** 表达：触发、选项、赋能、互斥/前置 | 与「修行路线」设计一致，且可维护 |
| 策略扩展 | 再增加 1～2 个规则型智能体（如保守型、激进型） | 多策略下的简单对比 |
| 报告与图表 | 按版本/参数生成 Markdown 报告 + 图（劫难曲线、各角色福慧分布） | 设计师可直接用于平衡讨论 |
| 配置化 | 易变数值（渡化门槛、回合数、事件效果表）抽到配置文件或表 | 改数不改代码即可重跑 |

**验收**：分支选择在模拟中正确触发并影响结果；报告能支撑「版本 A vs 版本 B」的决策；新增选择不会导致「到处 if flag」的泥潭。

### Phase 3：LLM 辅助与体验优化

| 项目 | 内容 | 产出 |
|------|------|------|
| 对话界面 | Streamlit（或你熟悉的）对话框，接 DeepSeek | 用户输入自然语言，得到建议与片段 |
| Prompt 设计 | 系统 prompt 含：当前规则摘要、指标摘要、可生成的片段类型；用户输入模糊/精确均可 | 回复有用、可操作 |
| 片段生成 | LLM 输出「新行动」「新分支」「新事件效果」等片段，人复制进项目并校验 | 减少手写重复劳动，不追求全自动 |
| 可选可视化 | 简单看板：选择规则版本 → 跑 N 局 → 看图表 | 非必须，按时间取舍 |

**验收**：设计师能用自然语言问「若加一个 X 机制会怎样」，获得可落地的建议或片段；至少 1 个真实需求通过 LLM 辅助完成修改并跑通。

### Phase 4（视情况）：抽象桌游设计引擎

- **触发条件**：功德轮回已稳定可玩、可测、可迭代，且你**确实**有「做第二款类似结构游戏」或「开源/复用」的需求。
- **做法**：  
  - 从现有代码中抽出：**流程层**（阶段、行动、牌堆、回合循环）+ **模拟层**（单局、批量、指标、智能体接口）。  
  - 定义**最小通用 schema**（不追求覆盖所有 RPG）：例如「阶段列表、行动列表、资源列表、牌堆、胜负条件、可选分支」。  
  - 功德轮回作为该 schema 的**第一个实现**；数据与文案保留在「游戏内容」包，引擎不依赖佛教专有概念。  
- **不承诺**：  
  - 不承诺该引擎能支持 Gloomhaven、TI4 等；只保证「功德轮回类半合作、回合制、卡牌+骰子」可复用。  
  - 不做「自然语言 → 完整规则」的通用产品；LLM 仍定位为辅助。

---

## 六、综合全部批判后的补充约束

以下为对多轮批判（工作区批判、Red Team、机制覆盖矩阵、LLM 校验闭环、时间估计等）的**收口约束**，保证方案可落地。

### 6.1 范围与表述

- **不穷举、不承诺「通用」**：不以「穷举所有 RPG 桌游」为目标；若日后谈通用性，用**机制覆盖矩阵**（机制维度 × 代表游戏）说明「支持哪一类」，而非罗列游戏名单。
- **定位一句话**：**功德轮回专用模拟器，设计时保持抽象以便将来扩展，不一开始追求通用 RPG 桌游引擎**；LLM 对话框为**辅助工具**，先验证模拟与回测的价值，再考虑 AI 增强。

### 6.2 规则与实现

- **配置 + 脚本混合**：数据用 YAML/表，复杂逻辑与卡牌效果用 **Python**；不强行全 YAML，避免表达力不足或配置爆炸。
- **规则冲突与边界**：约定效果顺序、边界情况（如资源为负、同时触发多事件）的处理方式；必要时引入简单「执行层」约定，不追求 MTG 级 Layer，但需文档化。
- **战役/Legacy**：本项目 MVP 不包含「永久改变、贴纸、跨局存档」；若未来做，单独设计**战役状态管理**，而非简单 save/load。

### 6.3 LLM 与校验

- **LLM 生成 = 草稿**：所有 LLM 输出视为**需人工审核的草稿**；若做自动校验闭环，必须带 **Schema 约束 + 静态/动态校验 + 修正次数上限**，避免死循环与越改越错。
- **模糊需求**：LLM 输出**多个候选方案**供人选择，不承诺「一句模糊话就生成可用规则」。

### 6.4 回测与模拟

- **回测目标**：**经济压力测试**（死机、资源膨胀/崩溃、规则自洽、版本对比）；**不**指望 AI 测社交平衡、谈判、欺骗体验。
- **智能体**：MVP 仅随机 + 规则型；**RL 为 Phase 5+ 可选**，非 MVP 成败关键。
- **隐藏信息/叛徒**：明确为**非目标**或 Phase 5+；完全信息模拟下，半合作的「隐藏发愿/个人目标」体验会弱化，属已知局限。

### 6.5 时间与验证

- **Phase 1 时间**：**4–8 周**（不再用 2–4 周）；含规则固化、边界处理、最小引擎、对局日志、批量跑局、**调试支持（可暂停、查状态）**、与旧脚本对齐验证。
- **成功标准**：v3.6 跑通、1000 局稳定、关键指标与旧脚本差异 &lt;5% 或可解释。
- **通用性验证**：仅在**抽象引擎（Phase 4）**时做，且以「第二款同类结构游戏能落地」为验证，不承诺支持任意 RPG。

### 6.6 若引用外部项目

- 可行性/调研文档中若引用「类似项目」（如 SIMPLE、OpenSpiel、MeepleLM、Figma AI 等），需**可核实来源**：官方链接 + 一句话可复用点（API/接口/示例），避免二手信息伤可信度。

---

## 七、风险与应对（与批判结论一致）

| 风险 | 应对 |
|------|------|
| 范围蔓延：想做「通用引擎」 | 明确主产品是佛教桌游；引擎是「做完再抽」，且只针对同类结构。 |
| LLM 生成不可用 | 只做「片段 + 建议」，不自动生效；人审阅、人合并、人校验。 |
| 规则复杂导致实现卡壳 | 复杂条件用 Python 实现；不强行 YAML 化；先跑通再考虑配置化。 |
| 时间被「引擎」分散 | 每个 Phase 都以「功德轮回可玩/可测/可迭代」为优先；抽象只在 Phase 4 且条件满足时做。 |
| 模块化不足导致难以抽象 | 从 Phase 1 就按 3.2 划分模块并用通用命名；即使不抽象，也利于维护。 |
| 规则/实现 bug 难定位 | Phase 1 必须做「单局可暂停、查状态」的调试支持，避免只靠 JSON 日志排错。 |

---

## 八、总结：可行度更高的方案长什么样（已综合全部批判）

1. **主产品**：一款与佛教世界观、经济学相关的半合作桌游（功德轮回），**可玩、可测、可迭代**。
2. **实现方式**：模块化（游戏内容 / 流程 / 模拟 / 工具），用通用术语和清晰边界，为日后抽象留口子。
3. **模拟**：完全信息、随机+规则型智能体、批量回测与报告；不承诺隐藏信息、叛徒、RL。
4. **LLM**：辅助（建议、片段生成、解释），人审阅后并入；不做全自动规则生成。
5. **引擎**：**项目完成后视需求再抽象**；若抽象，只保证「功德轮回类」半合作桌游可复用，不承诺通用覆盖。

本方案已综合多轮批判结论，包括：工作区可行性分析的批判性审查、Red Team 审查、「YAML+脚本」混合、规则形式化与冲突处理、LLM 校验闭环与人工终审、回测目标务实化（经济压力测试）、Phase 1 时间 4–8 周与成功标准、可视化/可暂停调试、选择树抽象为 progression module、机制覆盖矩阵与不穷举、外部引用可核实等。佛教桌游是主线目标，模块化保证可维护与可扩展，引擎为「可能的结果」而非前提，整体可行度更高、更可落地。
