# 桌游设计引擎 × AI — 详细计划方案

> 目标：以「功德轮回」半合作 RPG 桌游为首个用例，开发一个结合 AI 的桌游设计模拟器  
> 日期：2026-01-29

---

## 一、可借鉴的开源项目与技术资源

### 1. 强化学习 / 自博弈框架

| 项目 | 星数 | 特点 | 与本项目的关联 |
|------|------|------|----------------|
| **SIMPLE** (davidADSP) | 328⭐ | Python + PPO 自博弈，专为多人桌游设计；已实现 SushiGo、Connect4、Geschenkt 等 | **最直接可借鉴**：环境接口（`step/reset/observation/legal_actions`）、自博弈训练循环、Docker 化 |
| **OpenSpiel** (DeepMind) | 5k⭐ | C++ / Python，70+ 游戏，含 MCTS、CFR、RL 算法 | 成熟的多人博弈框架；可用于后期对标或移植算法 |
| **PettingZoo** (Farama) | 2.5k⭐ | 多智能体 RL 标准 API（AEC / Parallel）；含 Chess、Hanabi、Connect4 等 | 可作为引擎的「环境标准」，便于接 Stable-Baselines3、RLlib 等训练库 |
| **Hanabi Learning Env** (DeepMind) | 1k⭐ | 合作隐藏信息卡牌游戏；研究 Theory of Mind | 参考「合作 + 隐藏信息」模拟思路 |

### 2. LLM 与规则生成

| 项目 / 论文 | 说明 | 与本项目的关联 |
|-------------|------|----------------|
| **MeepleLM** (2026 论文) | LLM 当虚拟试玩员；MDA 推理 + 多 persona 反馈；70% 偏好率超 GPT-5.1 | **直接可用**：把规则摘要 + 对局数据喂给 LLM，按「策略型 / 休闲型」输出反馈 |
| **Code World Models (CWM)** | LLM 把自然语言规则翻译成 Python 世界模型（状态转移、合法行动、终止检查） | 可用于「自然语言规则 → DSL / 代码」的管道；结合 MCTS 做规划 |
| **GIF-MCTS** | 用 MCTS 引导 LLM 迭代生成 + 测试代码 | 规则代码自动验证与修复 |

### 3. 平衡性 / 回测方法

| 方法 | 说明 | 与本项目的关联 |
|------|------|----------------|
| **Monte Carlo 模拟** | 快速跑数千局，计算概率分布、胜率、回合数 | 引擎核心能力之一 |
| **Restricted-play Balance** | 用不同策略/能力级的智能体跑局，提取胜率、先手优势、策略深度等指标 | 定义「平衡性报告」的指标集 |
| **SHAP / 可解释 AI** | 解释「为什么某策略胜率高」 | 后期加入，生成人类可读的平衡性归因 |

### 4. 规则配置 / DSL

| 项目 | 说明 |
|------|------|
| **Metaplay Game Configs** | 分层配置（Item / Library / Archive）；YAML + 热更新 |
| **Narrat Engine** | YAML 配置 + 引擎校验；模块化（items.yaml, skills.yaml） |
| **DarkConfig** (Unity/C#) | 游戏配置库，强调快速迭代 |

> **结论**：用 **YAML / JSON** 描述规则，引擎加载并校验；核心概念（阶段、行动、资源、牌堆、胜负）用通用术语，游戏特定名词（如「渡化」「劫难」）只出现在配置里。

### 5. 可视化 / 前端

| 方案 | 特点 |
|------|------|
| **Streamlit** | Python 直接写 UI；适合快速原型、仪表盘、交互式图表 |
| **Matplotlib / Plotly** | 静态/交互图表，嵌入 Streamlit 或 Jupyter |
| **Pygame** | 2D 游戏可视化（可选，若需动画回放） |

---

## 二、系统架构设计

```
┌─────────────────────────────────────────────────────────────────────────┐
│                          桌游设计引擎 (BoardGame-Engine)                 │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│   ┌──────────────┐    ┌──────────────┐    ┌──────────────────────────┐  │
│   │ 规则配置层   │───▶│ 核心模拟层   │───▶│ 回测与分析层             │  │
│   │ (YAML/JSON)  │    │ (Engine)     │    │ (Backtesting)            │  │
│   └──────────────┘    └──────────────┘    └──────────────────────────┘  │
│         │                    │                        │                 │
│         │                    │                        ▼                 │
│         │                    │           ┌──────────────────────────┐   │
│         │                    │           │ 报告生成                 │   │
│         │                    │           │ (指标 + 图表 + 对局日志) │   │
│         │                    │           └──────────────────────────┘   │
│         │                    │                        │                 │
│         ▼                    ▼                        ▼                 │
│   ┌──────────────────────────────────────────────────────────────────┐  │
│   │                      AI 模块 (可选)                               │  │
│   │  ┌─────────────────┐  ┌─────────────────┐  ┌──────────────────┐  │  │
│   │  │ LLM 反馈        │  │ 策略智能体      │  │ 规则生成 / 修改  │  │  │
│   │  │ (MeepleLM式)    │  │ (随机/贪心/RL)  │  │ (自然语言→DSL)   │  │  │
│   │  └─────────────────┘  └─────────────────┘  └──────────────────┘  │  │
│   └──────────────────────────────────────────────────────────────────┘  │
│                                                                         │
│   ┌──────────────────────────────────────────────────────────────────┐  │
│   │                      前端 / CLI                                   │  │
│   │  • Streamlit 仪表盘（配置编辑、跑局、看报告）                    │  │
│   │  • CLI（批量回测、自动化脚本）                                   │  │
│   └──────────────────────────────────────────────────────────────────┘  │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 三、核心模块说明

### 3.1 规则配置层

**目标**：用 YAML/JSON 描述一款桌游的全部规则，引擎能加载、校验并执行。

**设计原则**：
- 通用概念 ≠ 游戏名词：引擎只认 `phase`, `action`, `resource`, `deck`, `condition`；游戏把「渡化」映射到某个 action，把「劫难」映射到某个 global resource。
- 可组合：阶段、行动、事件效果都可组合，类似乐高积木。

**示例（功德轮回简化版）**：

```yaml
game:
  name: "功德轮回"
  version: "3.6"
  players: [2, 3, 4]
  default_players: 4
  max_rounds: 6

resources:
  global:
    - id: calamity          # 劫难
      initial: 0
      min: 0
      max: 20
    - id: liberated_count   # 渡化计数
      initial: 0
  player:
    - id: wealth
    - id: merit             # 福
    - id: wisdom            # 慧

roles:
  - id: farmer
    initial: { wealth: 5, merit: 2, wisdom: 2 }
  - id: merchant
    initial: { wealth: 8, merit: 1, wisdom: 1 }
  - id: scholar
    initial: { wealth: 3, merit: 1, wisdom: 4 }
  - id: monk
    initial: { wealth: 0, merit: 3, wisdom: 3 }

phases:
  - id: event_phase
    description: "抽事件牌并结算"
    actions: [draw_event]
  - id: sentient_phase
    description: "众生滞留+1，超时离场加劫难，补牌"
  - id: action_phase
    description: "每人2次行动"
    player_actions: 2
  - id: settlement_phase
    description: "生存消耗、投资收益、劫难检查"

actions:
  - id: liberate            # 渡化
    requires: { wisdom: ">=5" }
    cost: { merit: 2, wealth: 3 }   # 示例：不同角色 cost 可配
    effect:
      - increment: { target: global.liberated_count, amount: 1 }
      - gain: { merit: 1, wisdom: 1 }   # 来自众生牌，可变
  - id: meditate            # 修行
    dice: 2d6
    effect_table:
      "2-4": { gain: { wisdom: 1 } }
      "5-9": { gain: { wisdom: 2 } }
      "10-12": { gain: { wisdom: 3 } }
  # ... 更多行动

win_conditions:
  team:
    - { condition: "global.calamity <= 12" }
    - { condition: "global.liberated_count >= 6" }
  individual:
    score: "player.merit + player.wisdom + vow_bonus"
```

### 3.2 核心模拟层（Engine）

**职责**：
1. 加载并校验规则配置
2. 管理游戏状态（全局、玩家、牌堆）
3. 执行回合循环：阶段 → 行动 → 结算
4. 暴露接口给「智能体」或「回测脚本」

**关键接口（参考 SIMPLE / PettingZoo）**：

```python
class GameEnv:
    def __init__(self, config_path: str, seed: int = None): ...
    def reset(self) -> dict:       # 返回初始观察
    def step(self, action: int) -> tuple[dict, float, bool, dict]:
        # 返回 (observation, reward, done, info)
    def legal_actions(self) -> list[int]: ...
    def render(self, mode='human'): ...
    @property
    def current_player(self) -> int: ...
    @property
    def n_players(self) -> int: ...
```

**设计要点**：
- **可复现**：`seed` 固定后，同一配置 + 同一动作序列 → 同一轨迹。
- **对局日志**：每步记录 `(round, phase, player, action, state_delta)`，方便回放与分析。
- **可插拔策略**：智能体只需实现 `select_action(observation, legal_actions) -> action`。

### 3.3 回测与分析层

**功能**：
- 批量跑局（多配置、多种子、多策略组合）
- 汇总指标：
  - **团队胜率** / 失败率
  - **回合数分布**（平均、方差、直方图）
  - **劫难曲线**（每回合平均劫难）
  - **资源曲线**（福/慧/财富随回合变化）
  - **行动分布**（各行动执行次数、占比）
  - **角色差异**（各角色平均福慧、渡化贡献）
  - **先手优势**（若适用）
- 版本对比：规则 A vs 规则 B 的指标差异、显著性检验（可选）
- 输出：JSON 汇总 + Markdown 报告 + 图表（Matplotlib / Plotly）

**CLI 示例**：

```bash
python backtest.py --config merit_cycle_v3.6.yaml --runs 1000 --agents random random random random --seed 42 --output results/v3.6_random_1000.json
```

### 3.4 AI 模块（可选 / 渐进式）

#### 3.4.1 策略智能体

| 层级 | 智能体类型 | 用途 |
|------|------------|------|
| L0 | **随机** | 基线；快速跑局 |
| L1 | **规则型 / 贪心** | 模拟「一般玩家」；例如「优先渡化」「劫难>10时必护法」 |
| L2 | **MCTS** | 模拟「高手」；每步搜索 N 次模拟 |
| L3 | **RL (PPO 自博弈)** | 最强策略；用于发现极端不平衡 |

**推荐路径**：先实现 L0/L1，验证回测管道；再按需加 L2/L3。

#### 3.4.2 LLM 反馈（MeepleLM 式）

**输入**：
- 规则摘要（从 YAML 自动生成或手写）
- N 局对局汇总（胜率、回合数、关键事件）

**输出**：
- 按 persona（策略型、休闲型、社交型）的主观反馈
- 平衡性/复杂度/可玩性简短评价
- 可考虑的改动建议（例如「渡化门槛可降低以减少后期拖沓」）

**实现**：调用 OpenAI / Claude / 本地 LLM API；prompt 模板 + JSON 结构化输出。

#### 3.4.3 规则生成 / 修改（进阶）

- 自然语言 → YAML：用户描述「新增一个行动：支付 3 慧可抵消 2 劫难」，LLM 生成对应 YAML 片段。
- 自动验证：引擎加载并校验，若失败则 LLM 修正。

---

## 四、分阶段计划

### Phase 1：核心原型（2–4 周）

| 任务 | 交付物 |
|------|--------|
| 1.1 抽取「功德轮回 v3.6」规则到 **简化 YAML** | `games/merit_cycle/config.yaml` |
| 1.2 实现 **最小引擎**（加载 YAML → 回合循环 → 单局模拟） | `engine/core.py` |
| 1.3 实现 **随机智能体** | `engine/agents/random_agent.py` |
| 1.4 跑通「1 局模拟 + 对局日志」 | 控制台输出 + JSON 日志 |
| 1.5 跑通「100 局批量 + 汇总指标」 | `results/v3.6_random_100.json` |

**验收标准**：
- 引擎跑出的胜率、回合数与旧模拟器（Archive 里的 Python 脚本）基本一致（误差 <5%）。

### Phase 2：回测管道 + 报告（2–3 周）

| 任务 | 交付物 |
|------|--------|
| 2.1 丰富汇总指标（劫难曲线、资源曲线、行动分布） | 指标函数 |
| 2.2 版本对比脚本（A vs B 指标差异） | `backtest_compare.py` |
| 2.3 Markdown 报告模板 + 图表 | `reports/template.md`、Matplotlib 图 |
| 2.4 CLI 入口统一 | `cli.py backtest / compare / report` |

**验收标准**：
- 能用一行命令对比 v3.5 vs v3.6，输出带图的 Markdown 报告。

### Phase 3：规则型智能体 + LLM 反馈（3–4 周）

| 任务 | 交付物 |
|------|--------|
| 3.1 实现 2–3 个规则型智能体（保守型、激进型） | `engine/agents/` |
| 3.2 用规则型智能体跑局，对比随机 | 新指标 |
| 3.3 LLM 反馈模块：prompt 模板 + API 调用 + 结构化输出 | `engine/ai/llm_feedback.py` |
| 3.4 集成到 CLI：`cli.py feedback --config ... --runs 100` | 输出平衡性建议 |

**验收标准**：
- LLM 能根据 100 局数据输出「策略型玩家视角」的 3–5 条反馈，设计师认为有参考价值。

### Phase 4：前端 + 可视化（2–3 周）

| 任务 | 交付物 |
|------|--------|
| 4.1 Streamlit 仪表盘：配置编辑（YAML 在线）、一键跑局、看报告 | `app/dashboard.py` |
| 4.2 对局回放（文字 + 简易图示） | 页面组件 |
| 4.3 图表交互（Plotly） | 可缩放/筛选 |

**验收标准**：
- 设计师可在浏览器里改参数、跑 100 局、看图表、读 LLM 反馈，无需碰命令行。

### Phase 5：高级 AI + 第二款游戏（持续迭代）

| 任务 | 说明 |
|------|------|
| 5.1 MCTS 智能体 | 模拟高手 |
| 5.2 PPO 自博弈（参考 SIMPLE） | 发现极端策略 |
| 5.3 适配 PettingZoo API | 可接 RLlib / SB3 |
| 5.4 添加第二款游戏（如简化版卡坦、或另一款自己设计的桌游） | 验证引擎通用性 |
| 5.5 规则生成模块（LLM → YAML） | 自然语言改规则 |

---

## 五、目录结构建议

```
c:\projects\MBS\ritual\
├── Archive-260129\           # 旧资产（已归档）
├── docs\                      # 调研、计划、设计文档
│   ├── 桌游设计引擎_调研与方向.md
│   ├── 以功德轮回驱动引擎开发_Pros_and_Cons.md
│   └── 桌游设计引擎_详细计划方案.md  <-- 本文档
├── engine\                    # 引擎核心
│   ├── __init__.py
│   ├── core.py                # GameEnv 主类
│   ├── loader.py              # YAML 加载与校验
│   ├── state.py               # 游戏状态管理
│   ├── actions.py             # 行动解析与执行
│   ├── dice.py                # 骰子 / 随机
│   ├── deck.py                # 牌堆管理
│   └── agents\
│       ├── base.py            # Agent 抽象基类
│       ├── random_agent.py
│       ├── rule_agent.py
│       └── mcts_agent.py
├── ai\                        # AI 模块
│   ├── llm_feedback.py
│   └── rule_gen.py
├── backtest\                  # 回测与分析
│   ├── runner.py              # 批量跑局
│   ├── metrics.py             # 指标计算
│   ├── compare.py             # 版本对比
│   └── report.py              # 报告生成
├── games\                     # 游戏配置
│   └── merit_cycle\           # 功德轮回
│       ├── config.yaml
│       ├── events.yaml
│       ├── sentients.yaml
│       └── vows.yaml
├── app\                       # 前端（Streamlit）
│   └── dashboard.py
├── cli.py                     # 命令行入口
├── requirements.txt
└── README.md
```

---

## 六、技术栈 & 依赖

| 层级 | 选型 | 说明 |
|------|------|------|
| 语言 | Python 3.10+ | 与现有资产一致 |
| 配置 | PyYAML / Pydantic | YAML 加载 + 校验 |
| 模拟 | 自研（参考 SIMPLE / PettingZoo 接口） | 轻量、可控 |
| 回测 | NumPy / Pandas | 统计 |
| 可视化 | Matplotlib / Plotly / Streamlit | 图表 + 仪表盘 |
| LLM | OpenAI API / Claude API / Ollama (本地) | 反馈 / 规则生成 |
| RL（可选） | Stable-Baselines3 / RLlib | PPO 自博弈 |
| 测试 | pytest | 单元测试 |

---

## 七、风险与缓解

| 风险 | 缓解 |
|------|------|
| 规则 YAML 表达力不足 | 先覆盖「功德轮回」用到的机制；遇到新机制再扩展 schema，保持向后兼容 |
| LLM 反馈不稳定 / 不可用 | LLM 模块设为可选；先把「模拟 + 回测」做稳定 |
| 半合作 / 隐藏信息难模拟 | MVP 先做「完全信息」版本（所有玩家策略公开）；隐藏信息作为 Phase 5 扩展 |
| 引擎被绑死在功德轮回 | 严格区分 `engine/`（通用）和 `games/merit_cycle/`（配置）；每加机制都用通用术语 |

---

## 八、下一步行动

1. **创建目录结构**：按上述建议建好 `engine/`、`games/`、`backtest/`、`app/` 等目录。
2. **抽取规则 YAML**：把 `Archive-260129/设计提案/功德轮回_规则说明书_v3.6.txt` 转为 `games/merit_cycle/config.yaml`（先做简化版，覆盖核心回合、行动、胜负）。
3. **实现最小引擎**：`engine/core.py` + `engine/loader.py`，能加载 YAML、跑一局、输出日志。
4. **随机智能体 + 100 局回测**：验证指标与旧模拟器一致。
5. **迭代**：按 Phase 2–5 逐步推进。

---

## 附录：关键参考链接

- **SIMPLE**：https://github.com/davidADSP/SIMPLE
- **OpenSpiel**：https://github.com/google-deepmind/open_spiel
- **PettingZoo**：https://pettingzoo.farama.org/
- **MeepleLM 论文**：https://arxiv.org/html/2601.07251v1
- **Code World Models**：https://arxiv.org/abs/2510.04542
- **Hanabi Learning Env**：https://github.com/google-deepmind/hanabi-learning-environment
- **Streamlit**：https://streamlit.io/
